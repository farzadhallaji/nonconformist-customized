{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library ðŸ˜š\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "# from IPython.display import Image  \n",
    "from IPython.display import Image, display\n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config ðŸ˜š\n",
    "path_to_datasets = '/home/farzad/Desktop/semiWithTree/originDataset/'\n",
    "dataset_name = 'bupa'\n",
    "\n",
    "\n",
    "dataset_path  = path_to_datasets + dataset_name\n",
    "base_classifier = DecisionTreeClassifier\n",
    "random_state = 0\n",
    "min_samples_leaf=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_xy(test_data):\n",
    "    # assert : class = last atr ðŸ˜š\n",
    "    x_test = test_data.values[:, 0:-1]\n",
    "    y_test = (test_data.values[:, -1]).astype('int')\n",
    "    \n",
    "    return x_test,y_test\n",
    "\n",
    "def read_data(dataset_path) :\n",
    "    \n",
    "    train_raw_data = loadarff(dataset_path+'/train.arff')\n",
    "    test_raw_data = loadarff(dataset_path+'/test.arff')\n",
    "    \n",
    "    train_data = pd.DataFrame(train_raw_data[0])\n",
    "    test_data = pd.DataFrame(test_raw_data[0])\n",
    "    \n",
    "    train_data['Class'] = train_data['Class'].astype(int)\n",
    "    test_data['Class'] = test_data['Class'].astype(int)\n",
    "    \n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "def get_rate_p(train_y) : \n",
    "    \n",
    "    counter=collections.Counter(train_y)\n",
    "    tuple_list_pn = counter.most_common()\n",
    "    \n",
    "    return tuple_list_pn[0][1]/(tuple_list_pn[0][1]+tuple_list_pn[1][1]) , tuple_list_pn\n",
    "\n",
    "def split_trainset(train_data) :\n",
    "    \n",
    "    labeled , unlabeled = [],[]\n",
    "    \n",
    "    size_dataset = len(train_data)\n",
    "    train_x,train_y = divide_xy(train_data)\n",
    "    \n",
    "    rate_p , tuple_list_pn = get_rate_p(train_y)\n",
    "    \n",
    "    size_labeled_data = round(0.1 * size_dataset)\n",
    "    size_unlabeled_data = size_dataset - size_labeled_data\n",
    "    \n",
    "    size_labeled_p_data = round(rate_p*size_labeled_data)\n",
    "    size_labeled_n_data = size_labeled_data - size_labeled_p_data\n",
    "    \n",
    "    labeled_index = []\n",
    "    unlabeled_index = []\n",
    "    selected_pl = 0\n",
    "    selected_nl = 0\n",
    "    \n",
    "    for i,cls in enumerate(train_y):\n",
    "        # if data point class's == 0 ðŸ˜š\n",
    "        if cls == tuple_list_pn[0][0] :\n",
    "            if selected_pl < size_labeled_p_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_pl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "        else :\n",
    "            if selected_nl < size_labeled_n_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_nl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "                \n",
    "    for i in labeled_index:\n",
    "        labeled.append(train_data.values[i])\n",
    "    \n",
    "    for i in unlabeled_index:\n",
    "        unlabeled.append(train_data.values[i])\n",
    "    \n",
    "#     print(size_dataset , size_labeled_data , size_unlabeled_data)\n",
    "#     print(rate_p , tuple_list_pn)\n",
    "#     print(size_labeled_p_data , size_labeled_n_data)\n",
    "#     print(selected_pl/(selected_pl+selected_nl),selected_pl, selected_nl)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(labeled,columns=train_data.columns),pd.DataFrame(unlabeled,columns=train_data.columns),rate_p,tuple_list_pn\n",
    "\n",
    "def evaluate_classifier(base_classifier, labeled_data, test_data):\n",
    "    \n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    test_x,test_y = divide_xy(test_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    dtree=base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    dtree.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dtree, out_file=dot_data,filled=True, rounded=True,special_characters=True)\n",
    "#     graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "#     img = Image(graph.create_png())\n",
    "    img=None\n",
    "    y_pred = dtree.predict(test_x)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "    \n",
    "    return accuracy , img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.cp import TcpClassifier\n",
    "from nonconformist.nc import ClassifierNc, MarginErrFunc\n",
    "\n",
    "def confidency(name , DTclassifier , labeled_data , unlabeled_data , i , confidence) :\n",
    "\n",
    "    lbl = None\n",
    "    test_x,test_y = divide_xy(unlabeled_data)\n",
    "    train_x,train_y = divide_xy(labeled_data)\n",
    "    is_confident = False\n",
    "    if name == 'Probability' :\n",
    "        lbl = DTclassifier.predict([test_x[i]])\n",
    "        i_confidence = DTclassifier.predict_proba([test_x[i]])\n",
    "        if max(i_confidence[0]) > confidence :\n",
    "            is_confident = True\n",
    "            \n",
    "            \n",
    "    elif name == 'tcp' :\n",
    "        model = ClassifierAdapter(base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf))\n",
    "        nc = ClassifierNc(model, MarginErrFunc())\n",
    "        tcp = TcpClassifier(nc)\n",
    "        tcp.fit(train_x,train_y)\n",
    "        \n",
    "        prediction_conf = tcp.predict_conf(test_x[[i], :])\n",
    "        lbl = [prediction_conf[0][0]]\n",
    "        \n",
    "        \n",
    "        ss=0\n",
    "        me=0\n",
    "        for i in range(100) :\n",
    "            prediction = tcp.predict(test_x[[i], :])\n",
    "            me += abs(prediction[0][0]-prediction[0][1]) * max(prediction[0][0],prediction[0][1])\n",
    "\n",
    "            prediction = tcp.predict_conf(test_x[[i], :])\n",
    "            ss += prediction[0][1]*prediction[0][2]\n",
    "        print(ss-me , end=\" , \")\n",
    "        \n",
    "        if ss-me > confidence :\n",
    "            is_confident = True\n",
    "        \n",
    "    return is_confident , lbl\n",
    "\n",
    "\n",
    "def selection_metric(labeled_data,unlabeled_data ,rate_p,tuple_list_pn , confidence,selection_rate , confidence_method_name) :\n",
    "    \n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    unlabeled_x,unlabeled_y = divide_xy(unlabeled_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    DTclassifier = base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    DTclassifier.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    total_selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_index = []\n",
    "    selected_y = []\n",
    "    \n",
    "    \n",
    "    for i  in range(len(removed_selected_data)) :\n",
    "        is_confident , lbl = confidency(confidence_method_name , DTclassifier , labeled_data ,\n",
    "                                        removed_selected_data , i , confidence)\n",
    "        if is_confident: \n",
    "            selected_index.append(i)\n",
    "            selected_y.append(lbl[0])\n",
    "            # set class\n",
    "            removed_selected_data.at[i, 'Class'] = lbl[0]\n",
    "            \n",
    "    \n",
    "    selected_index_p = []\n",
    "    selected_index_n = []\n",
    "    \n",
    "    \n",
    "    size_selected  = round(selection_rate * len(labeled_data))\n",
    "    print(' PISH FARZ  size_selected : ', size_selected)\n",
    "    \n",
    "    #should be constant rate \n",
    "    new_rate_p,new_tuple_list_pn = get_rate_p(np.array(selected_y))\n",
    "        \n",
    "    len_new_selected_p = new_tuple_list_pn[0][1]\n",
    "    len_new_selected_n = new_tuple_list_pn[1][1]\n",
    "    \n",
    "    len_lebeled_p = tuple_list_pn[0][1]\n",
    "    len_lebeled_n = tuple_list_pn[1][1]\n",
    "\n",
    "    size_select_p = 0\n",
    "    size_select_n = 0\n",
    "    \n",
    "    \n",
    "    print('rate_p:',rate_p , '  new_rate_p:',new_rate_p)\n",
    "    print('tuple_list_pn:',tuple_list_pn , '  new_tuple_list_pn:',new_tuple_list_pn)\n",
    "    \n",
    "    if new_rate_p > rate_p :\n",
    "        size_select_n = round(min(len_new_selected_n , size_selected * (1-rate_p)))\n",
    "        size_select_p = round(size_select_n * (rate_p/(1-rate_p)))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "            \n",
    "    else :\n",
    "        size_select_p = round(min(len_new_selected_p , size_selected * rate_p))\n",
    "        size_select_n = round(size_select_p * ((1-rate_p)/rate_p))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "\n",
    "            \n",
    "        \n",
    "    print('size_select_p : ' , size_select_p , '   size_select_n : ' , size_select_n, '   size_selected : ' , size_selected)\n",
    "    \n",
    "    \n",
    "    p = new_tuple_list_pn[0][0]\n",
    "    \n",
    "    i=0\n",
    "    while(size_select_p > 0):\n",
    "        if selected_y[i] == p :\n",
    "            selected_index_p.append(i)      \n",
    "            size_select_p-=1\n",
    "        i+=1\n",
    "                \n",
    "    i=0\n",
    "    while(size_select_n > 0):\n",
    "        if selected_y[i] != p :\n",
    "            selected_index_n.append(i)  \n",
    "            size_select_n-=1\n",
    "        i+=1\n",
    "        \n",
    "    print('selected_index_p : ',len(selected_index_p))\n",
    "    print('selected_index_n : ',len(selected_index_n))\n",
    "    \n",
    "    \n",
    "    for i in range(len(selected_index_p)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_p[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_p: ', len(selected_labeling))\n",
    "        \n",
    "    for i in range(len(selected_index_n)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_n[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_n: ', len(selected_labeling))\n",
    "\n",
    "    removed_selected_data.drop(removed_selected_data.index[selected_index])\n",
    "    \n",
    "    total_selected_labeling = pd.concat([labeled_data ,selected_labeling],ignore_index=True)\n",
    "    \n",
    "    return total_selected_labeling,removed_selected_data\n",
    "\n",
    "\n",
    "def self_labeling(labeled_data , unlabeled_data , iteration , rate_p,tuple_list_pn , confidence,selection_rate,confidence_method_name):\n",
    "\n",
    "    \n",
    "    labeled_unlabel_data = labeled_data.copy()\n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    \n",
    "    while iteration:\n",
    "        \n",
    "        selected_labeling,removed_selected_data = selection_metric(labeled_unlabel_data,removed_selected_data,\n",
    "                                                                   rate_p,tuple_list_pn ,\n",
    "                                                                   confidence,selection_rate,\n",
    "                                                                   confidence_method_name)\n",
    "        labeled_unlabel_data = pd.concat([labeled_unlabel_data , selected_labeling])\n",
    "        \n",
    "        print('iteration:' , iteration , ' , selected_labeling:' , len(selected_labeling)\n",
    "             , ' , labeled_data:' , len(labeled_data))\n",
    "        iteration-=1\n",
    "        \n",
    "    return labeled_unlabel_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.759595445975734 , 19.15962016099298 , 18.47870384329148 , 15.130972764232087 , 16.19457130354224 , 16.99218130938598 , 19.612514411276763 , 16.068450490767347 , 17.305954024164073 , 15.487665992969845 , 17.829226109148912 , 17.987574681212084 , 17.35996995863728 , 14.880577951999573 , 18.315887312238097 , 19.41950562947762 , 19.305547432857843 , 17.795967628185835 , 18.351986928117668 , 16.800088269654108 , 13.94363499397836 , 16.60642637099109 , 19.426793685509605 , 14.701116807399629 , 19.426496817756625 , 15.677736861094377 , 17.82007020212993 , 17.276754836631902 , 16.181567482720546 , 17.115172510348604 , 21.070422468895732 , 17.429223328473334 , 16.919093442304977 , 18.026155240474452 , 16.813121741094246 , 17.074049287780362 , 17.1459477803467 , 17.80994865288608 , 21.584498386955794 , 15.005894494649436 , 17.083072004950914 , 18.774798031992848 , 14.753496211935115 , 14.611500895847833 , 15.949660890085482 , 15.91258671502785 , 17.370570637653934 , 18.540862694129338 , 17.569682921571367 , 14.712681649085027 , 19.536846630765318 , 17.66400751195275 , 17.644341229718318 , 20.76209148913753 , 15.157575826327225 , 16.723851147625208 , 17.92074097304273 , 18.892241265357217 , 15.442249366437228 , 14.365299763444352 , 12.146360117394448 , 18.61464455591984 , 20.8568954547788 , 13.99460061380529 , 19.005513184467112 , 14.858655876315314 , 15.811635579715052 , 16.938043132104077 , 18.020688766290846 , 16.180625993008984 , 18.51393962966759 , 18.456652144320604 , 16.722612231988855 , 14.876377391843931 , 16.900468225776866 , 22.785415319747898 , 20.50686771875459 , 18.085212860431092 , 17.376672167578185 , 14.63382320556818 , 20.38632135849137 , 15.77752633979631 , 17.981950581635125 , 17.943648223916362 , 16.10985273735642 , 18.221568545226166 , 15.528232677348502 , 18.64204310503485 , 18.1591916289224 , 18.95350581696161 , 15.580642949112537 , 16.449131640372997 , 17.597828703705872 , 19.360557451192385 , 14.166251515255048 , 18.043499352067727 , 18.965371287479496 , 17.19902268273418 , 21.46901400943828 , 16.386307539546067 , 20.41504767138414 , 17.263094192836604 , 17.242395416016397 , 12.55999344283644 , 15.824440492718956 , 15.978268815530285 , 15.309540165313532 , 17.844114477270423 , 18.437040297579994 , 19.109801650091757 , 16.141527790639774 , 17.77786966831751 , 18.03680561885686 , 18.690538087070497 , 17.876921403560814 , 18.548525920177116 , 20.662636574352124 , 19.059816357239274 , 16.435399551566384 , 19.956254478142995 , 19.797352356648958 , 17.978894726813504 , 15.539058109279601 , 17.4756852291403 , 16.29670725693129 , 21.99604493333904 , 18.56766797000941 , 16.525898214648777 , 20.107692304336382 , 19.173756676608654 , 16.686070109549878 , 17.071340642557864 , 18.758133176632978 , 18.786237597852004 , 16.330133722963446 , 18.506769489669928 , 19.028450490940372 , 16.089713073739983 , 16.85400503137986 , 18.888938408706597 , 21.320000630783166 , 13.771600323034594 , 18.920394472046635 , 16.642334519748392 , 21.21405549217089 , 13.726801550980625 , 18.864645906764363 , 18.557955418677338 , 19.125892654077745 , 15.183376658988067 , 21.27434677468582 , 14.955791627575909 , 17.914259900912807 , 15.641666947817082 , 16.57783799198546 , 14.63597562734099 , 18.48871774145987 , 18.888209562385313 , 18.746387224622232 , 13.43635192569862 , 17.85959647006464 , 18.351366671730982 , 18.716623988205146 , 19.235260729505637 , 18.558008553725074 , 17.166317680690806 , 15.966614181347541 , 18.8876578719498 , 19.73324939512065 , 16.489133611192717 , 19.449774875654743 , 14.670279918129236 , 16.094336372654215 , 17.378329009996733 , 16.62737901103425 , 18.42102371046724 , 15.004540059300318 , 20.63705157373596 , 15.123609414100748 , 17.366467828497715 , 17.234943619089396 , 11.96518314578282 , 17.448201073397858 , 14.776134100706496 , 16.40751356986972 , 19.056123422028243 , 18.109502916518718 , 15.842579428093234 , 21.228398161616056 , 18.7858473150255 , 18.617831657509004 , 20.61551317431633 , 19.16987336880515 , 17.407830741859822 , 17.467895966641724 , 14.207859533353968 , 14.222014448775724 , 16.23808913444161 , 16.719355506218935 , 18.413307070293776 , 18.80401227927603 , 20.11664154265417 , 21.383318822641243 , 19.390353909053307 , 18.081050260676495 , 18.31073390389249 , 21.93000161293388 , 17.556107070907608 , 20.461745212906976 ,  PISH FARZ  size_selected :  23\n",
      "rate_p: 0.5775862068965517   new_rate_p: 0.6889952153110048\n",
      "tuple_list_pn: [(2, 134), (1, 98)]   new_tuple_list_pn: [(0.0, 144), (1.0, 65)]\n",
      "size_select_p :  14    size_select_n :  10    size_selected :  24\n",
      "selected_index_p :  14\n",
      "selected_index_n :  10\n",
      "selected_labeling_p:  14\n",
      "selected_labeling_n:  24\n",
      "iteration: 1  , selected_labeling: 47  , labeled_data: 23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data,test_data = read_data(dataset_path)\n",
    "train_x,train_y = divide_xy(train_data)\n",
    "test_x , test_y = divide_xy(test_data)\n",
    "\n",
    "labeled_data,unlabeled_data , rate_p,tuple_list_pn = split_trainset(train_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "a1 , img1 = evaluate_classifier(base_classifier , labeled_data  , test_data)\n",
    "\n",
    "total_labeled_data = self_labeling(labeled_data , unlabeled_data , 1, \n",
    "                                   rate_p,tuple_list_pn ,\n",
    "                                   confidence=10,selection_rate = 1,confidence_method_name='tcp')\n",
    "\n",
    "a2 , img2 = evaluate_classifier(base_classifier , total_labeled_data  , test_data)\n",
    "\n",
    "\n",
    "# display(img1)\n",
    "# display(img2)\n",
    "# print(a1 , a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nonconformist.cp import TcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "\n",
    "\n",
    "model = base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\t# Create the underlying model\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "tcp = TcpClassifier(nc)\t\t\t# Create a transductive conformal classifier\n",
    "\n",
    "tcp.fit(train_x,train_y)\n",
    "prediction = tcp.predict(test_x[[1], :], significance=0.9)\n",
    "prediction = tcp.predict_conf(test_x[[1], :])\n",
    "\n",
    "prediction\n",
    "\n",
    "# test_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "60.273926880379086 57.8819599395923 2.391966940786787 1\n"
     ]
    }
   ],
   "source": [
    "from nonconformist.base import ClassifierAdapter\n",
    "from nonconformist.cp import TcpClassifier\n",
    "from nonconformist.nc import ClassifierNc, MarginErrFunc\n",
    "\n",
    "model = ClassifierAdapter(base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf))\n",
    "nc = ClassifierNc(model, MarginErrFunc())\n",
    "tcp = TcpClassifier(nc)\n",
    "tcp.fit(train_x,train_y)\n",
    "\n",
    "sss = 2\n",
    "\n",
    "print()\n",
    "ss=0\n",
    "me=0\n",
    "for i in range(100) :\n",
    "    prediction = tcp.predict(test_x[[sss], :])\n",
    "    me += abs(prediction[0][0]-prediction[0][1]) * max(prediction[0][0],prediction[0][1])\n",
    "    \n",
    "    prediction = tcp.predict_conf(test_x[[sss], :])\n",
    "    ss += prediction[0][1]*prediction[0][2]\n",
    "print(ss,me ,ss-me, test_y[sss])\n",
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
