{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library ðŸ˜š\n",
    "\n",
    "import sklearn.datasets as datasets\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "# from IPython.display import Image  \n",
    "from IPython.display import Image, display\n",
    "from sklearn.tree import export_graphviz\n",
    "# import pydotplus\n",
    "\n",
    "from scipy.io.arff import loadarff\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config ðŸ˜š\n",
    "path_to_datasets = '/home/farzad/Desktop/semiWithTree/originDataset/'\n",
    "dataset_name = 'bupa'\n",
    "\n",
    "\n",
    "dataset_path  = path_to_datasets + dataset_name\n",
    "base_classifier = DecisionTreeClassifier\n",
    "random_state = 0\n",
    "min_samples_leaf=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_xy(test_data):\n",
    "    # assert : class = last atr ðŸ˜š\n",
    "    x_test = test_data.values[:, 0:-1]\n",
    "    y_test = (test_data.values[:, -1]).astype('int')\n",
    "    \n",
    "    return x_test,y_test\n",
    "\n",
    "def read_data(dataset_path) :\n",
    "    \n",
    "    train_raw_data = loadarff(dataset_path+'/train.arff')\n",
    "    test_raw_data = loadarff(dataset_path+'/test.arff')\n",
    "    \n",
    "    train_data = pd.DataFrame(train_raw_data[0])\n",
    "    test_data = pd.DataFrame(test_raw_data[0])\n",
    "    \n",
    "    train_data['Class'] = train_data['Class'].astype(int)\n",
    "    test_data['Class'] = test_data['Class'].astype(int)\n",
    "    \n",
    "    return train_data,test_data\n",
    "\n",
    "\n",
    "def get_rate_p(train_y) : \n",
    "    \n",
    "    counter=collections.Counter(train_y)\n",
    "    tuple_list_pn = counter.most_common()\n",
    "    \n",
    "    return tuple_list_pn[0][1]/(tuple_list_pn[0][1]+tuple_list_pn[1][1]) , tuple_list_pn\n",
    "\n",
    "def split_trainset(train_data) :\n",
    "    \n",
    "    labeled , unlabeled = [],[]\n",
    "    \n",
    "    size_dataset = len(train_data)\n",
    "    train_x,train_y = divide_xy(train_data)\n",
    "    \n",
    "    rate_p , tuple_list_pn = get_rate_p(train_y)\n",
    "    \n",
    "    size_labeled_data = round(0.1 * size_dataset)\n",
    "    size_unlabeled_data = size_dataset - size_labeled_data\n",
    "    \n",
    "    size_labeled_p_data = round(rate_p*size_labeled_data)\n",
    "    size_labeled_n_data = size_labeled_data - size_labeled_p_data\n",
    "    \n",
    "    labeled_index = []\n",
    "    unlabeled_index = []\n",
    "    selected_pl = 0\n",
    "    selected_nl = 0\n",
    "    \n",
    "    for i,cls in enumerate(train_y):\n",
    "        # if data point class's == 0 ðŸ˜š\n",
    "        if cls == tuple_list_pn[0][0] :\n",
    "            if selected_pl < size_labeled_p_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_pl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "        else :\n",
    "            if selected_nl < size_labeled_n_data :\n",
    "                labeled_index.append(i)\n",
    "                selected_nl+=1\n",
    "            else :\n",
    "                unlabeled_index.append(i)\n",
    "                \n",
    "    for i in labeled_index:\n",
    "        labeled.append(train_data.values[i])\n",
    "    \n",
    "    for i in unlabeled_index:\n",
    "        unlabeled.append(train_data.values[i])\n",
    "    \n",
    "#     print(size_dataset , size_labeled_data , size_unlabeled_data)\n",
    "#     print(rate_p , tuple_list_pn)\n",
    "#     print(size_labeled_p_data , size_labeled_n_data)\n",
    "#     print(selected_pl/(selected_pl+selected_nl),selected_pl, selected_nl)\n",
    "    \n",
    "    \n",
    "    return pd.DataFrame(labeled,columns=train_data.columns),pd.DataFrame(unlabeled,columns=train_data.columns),rate_p,tuple_list_pn\n",
    "\n",
    "def evaluate_classifier(base_classifier, labeled_data, test_data):\n",
    "\n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    test_x,test_y = divide_xy(test_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    dtree=base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    dtree.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    dot_data = StringIO()\n",
    "    export_graphviz(dtree, out_file=dot_data,filled=True, rounded=True,special_characters=True)\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "    img = Image(graph.create_png())\n",
    "    \n",
    "    y_pred = dtree.predict(test_x)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(test_y, y_pred)\n",
    "    \n",
    "    return accuracy , img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidency(name , DTclassifier , labeled_data , unlabeled_data , i , confidence) :\n",
    "\n",
    "    test_x,test_y = divide_xy(unlabeled_data)\n",
    "    is_confident = False\n",
    "    lbl = DTclassifier.predict([test_x[i]])\n",
    "    if name == 'Probability' :\n",
    "        i_confidence = DTclassifier.predict_proba([test_x[i]])\n",
    "        if max(i_confidence[0]) > confidence :\n",
    "            is_confident = True\n",
    "    \n",
    "    return is_confident , lbl\n",
    "\n",
    "\n",
    "def selection_metric(labeled_data,unlabeled_data ,rate_p,tuple_list_pn , confidence,selection_rate , confidence_method_name) :\n",
    "    \n",
    "    labeled_x,labeled_y = divide_xy(labeled_data)\n",
    "    unlabeled_x,unlabeled_y = divide_xy(unlabeled_data)\n",
    "\n",
    "    # dtree = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
    "    DTclassifier = base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\n",
    "    DTclassifier.fit(labeled_x,labeled_y)\n",
    "    \n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    total_selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_labeling = pd.DataFrame(columns=labeled_data.columns)\n",
    "    selected_index = []\n",
    "    selected_y = []\n",
    "    \n",
    "    \n",
    "    for i  in range(len(removed_selected_data)) :\n",
    "        is_confident , lbl = confidency(confidence_method_name , DTclassifier , labeled_data ,\n",
    "                                        removed_selected_data , i , confidence)\n",
    "        if is_confident: \n",
    "            selected_index.append(i)\n",
    "            selected_y.append(lbl[0])\n",
    "            # set class\n",
    "            removed_selected_data.at[i, 'Class'] = lbl[0]\n",
    "\n",
    "            \n",
    "    \n",
    "    selected_index_p = []\n",
    "    selected_index_n = []\n",
    "    \n",
    "    \n",
    "    size_selected  = round(selection_rate * len(labeled_data))\n",
    "    print(' PISH FARZ  size_selected : ', size_selected)\n",
    "    \n",
    "    #should be constant rate \n",
    "    new_rate_p,new_tuple_list_pn = get_rate_p(np.array(selected_y))\n",
    "        \n",
    "    len_new_selected_p = new_tuple_list_pn[0][1]\n",
    "    len_new_selected_n = new_tuple_list_pn[1][1]\n",
    "    \n",
    "    len_lebeled_p = tuple_list_pn[0][1]\n",
    "    len_lebeled_n = tuple_list_pn[1][1]\n",
    "\n",
    "    size_select_p = 0\n",
    "    size_select_n = 0\n",
    "    \n",
    "    \n",
    "    print('rate_p:',rate_p , '  new_rate_p:',new_rate_p)\n",
    "    print('tuple_list_pn:',tuple_list_pn , '  new_tuple_list_pn:',new_tuple_list_pn)\n",
    "    \n",
    "    if new_rate_p > rate_p :\n",
    "        size_select_n = round(min(len_new_selected_n , size_selected * (1-rate_p)))\n",
    "        size_select_p = round(size_select_n * (rate_p/(1-rate_p)))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "            \n",
    "    else :\n",
    "        size_select_p = round(min(len_new_selected_p , size_selected * rate_p))\n",
    "        size_select_n = round(size_select_p * ((1-rate_p)/rate_p))\n",
    "        size_selected = size_select_n + size_select_p\n",
    "\n",
    "            \n",
    "        \n",
    "    print('size_select_p : ' , size_select_p , '   size_select_n : ' , size_select_n, '   size_selected : ' , size_selected)\n",
    "    \n",
    "    \n",
    "    p = new_tuple_list_pn[0][0]\n",
    "    \n",
    "    i=0\n",
    "    while(size_select_p > 0):\n",
    "        if selected_y[i] == p :\n",
    "            selected_index_p.append(i)      \n",
    "            size_select_p-=1\n",
    "        i+=1\n",
    "                \n",
    "    i=0\n",
    "    while(size_select_n > 0):\n",
    "        if selected_y[i] != p :\n",
    "            selected_index_n.append(i)  \n",
    "            size_select_n-=1\n",
    "        i+=1\n",
    "        \n",
    "    print('selected_index_p : ',len(selected_index_p))\n",
    "    print('selected_index_n : ',len(selected_index_n))\n",
    "    \n",
    "    \n",
    "    for i in range(len(selected_index_p)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_p[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_p: ', len(selected_labeling))\n",
    "        \n",
    "    for i in range(len(selected_index_n)):\n",
    "        selected_labeling=selected_labeling.append(removed_selected_data.iloc[selected_index_n[i]] ,ignore_index=True)\n",
    "    print('selected_labeling_n: ', len(selected_labeling))\n",
    "\n",
    "    removed_selected_data.drop(removed_selected_data.index[selected_index])\n",
    "    \n",
    "    total_selected_labeling = pd.concat([labeled_data ,selected_labeling],ignore_index=True)\n",
    "    \n",
    "    return total_selected_labeling,removed_selected_data\n",
    "\n",
    "\n",
    "def self_labeling(labeled_data , unlabeled_data , iteration , rate_p,tuple_list_pn , confidence,selection_rate,confidence_method_name):\n",
    "\n",
    "    \n",
    "    labeled_unlabel_data = labeled_data.copy()\n",
    "    removed_selected_data = unlabeled_data.copy()\n",
    "    \n",
    "    while iteration:\n",
    "        \n",
    "        selected_labeling,removed_selected_data = selection_metric(labeled_unlabel_data,removed_selected_data,\n",
    "                                                                   rate_p,tuple_list_pn ,\n",
    "                                                                   confidence,selection_rate,\n",
    "                                                                   confidence_method_name)\n",
    "        labeled_unlabel_data = pd.concat([labeled_unlabel_data , selected_labeling])\n",
    "        \n",
    "        print('iteration:' , iteration , ' , selected_labeling:' , len(selected_labeling)\n",
    "             , ' , labeled_data:' , len(labeled_data))\n",
    "        iteration-=1\n",
    "        \n",
    "    return labeled_unlabel_data\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data,test_data = read_data(dataset_path)\n",
    "train_x,train_y = divide_xy(train_data)\n",
    "test_x , test_y = divide_xy(test_data)\n",
    "\n",
    "labeled_data,unlabeled_data , rate_p,tuple_list_pn = split_trainset(train_data)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# a1 , img1 = evaluate_classifier(base_classifier , labeled_data  , test_data)\n",
    "\n",
    "# total_labeled_data = self_labeling(labeled_data , unlabeled_data , 1, \n",
    "#                                    rate_p,tuple_list_pn ,\n",
    "#                                    confidence=0.9,selection_rate = 4,confidence_method_name='Probability')\n",
    "\n",
    "# a2 , img2 = evaluate_classifier(base_classifier , total_labeled_data  , test_data)\n",
    "\n",
    "\n",
    "# display(img1)\n",
    "# display(img2)\n",
    "# print(a1 , a2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.70801211, 0.7545237 ],\n",
       "       [1.        , 0.29018095, 0.80775826],\n",
       "       [0.        , 0.73739495, 0.9665924 ],\n",
       "       [1.        , 0.57094538, 0.83812616],\n",
       "       [1.        , 0.41319154, 0.7258874 ],\n",
       "       [1.        , 0.74971478, 0.86668647],\n",
       "       [0.        , 0.25416052, 0.98917649],\n",
       "       [1.        , 0.77341962, 0.80167673],\n",
       "       [1.        , 0.80776914, 0.75165327],\n",
       "       [1.        , 0.38622172, 0.78562962],\n",
       "       [1.        , 0.33185204, 0.79530303],\n",
       "       [1.        , 0.87720692, 0.82247857],\n",
       "       [0.        , 0.81744742, 0.98790128],\n",
       "       [1.        , 0.73335995, 0.49611699],\n",
       "       [1.        , 0.7373488 , 0.78175802],\n",
       "       [1.        , 0.98459333, 0.84066138],\n",
       "       [0.        , 0.585823  , 0.58776164],\n",
       "       [0.        , 0.31296374, 0.8911169 ],\n",
       "       [1.        , 0.92856306, 0.77939777],\n",
       "       [0.        , 0.4840681 , 0.91204371],\n",
       "       [1.        , 0.36489799, 0.76194259],\n",
       "       [0.        , 0.3833486 , 0.96353022],\n",
       "       [0.        , 0.46366591, 0.99236661],\n",
       "       [1.        , 0.57072959, 0.79403712],\n",
       "       [0.        , 0.46180197, 0.98912645],\n",
       "       [1.        , 0.84098728, 0.29621863],\n",
       "       [1.        , 0.71212483, 0.84438929],\n",
       "       [1.        , 0.49254209, 0.7444233 ],\n",
       "       [1.        , 0.44301228, 0.62004367],\n",
       "       [1.        , 0.33791585, 0.77361351],\n",
       "       [0.        , 0.28291394, 0.98665279],\n",
       "       [0.        , 0.72156246, 0.46506022],\n",
       "       [1.        , 0.2669461 , 0.85894404],\n",
       "       [0.        , 0.7211313 , 0.47229028],\n",
       "       [1.        , 0.68386257, 0.79398232],\n",
       "       [1.        , 0.12978134, 0.8962871 ],\n",
       "       [0.        , 0.7269761 , 0.71528355],\n",
       "       [1.        , 0.97212922, 0.87852134],\n",
       "       [1.        , 0.40301987, 0.84138954],\n",
       "       [0.        , 0.88412176, 0.37719918],\n",
       "       [1.        , 0.64992067, 0.52914988],\n",
       "       [1.        , 0.87627514, 0.8224801 ],\n",
       "       [0.        , 0.22778309, 0.94558678],\n",
       "       [1.        , 0.64126806, 0.86857793],\n",
       "       [0.        , 0.50802286, 0.88746269],\n",
       "       [1.        , 0.94515713, 0.76189737],\n",
       "       [0.        , 0.9561776 , 0.49045355],\n",
       "       [1.        , 0.9789145 , 0.82940871],\n",
       "       [1.        , 0.72044707, 0.70180178],\n",
       "       [1.        , 0.57201525, 0.54075779],\n",
       "       [0.        , 0.73940273, 0.9002057 ],\n",
       "       [0.        , 0.61756997, 0.88263249],\n",
       "       [0.        , 0.91894667, 0.28602247],\n",
       "       [0.        , 0.50394063, 0.86688342],\n",
       "       [0.        , 0.9960606 , 0.88760139],\n",
       "       [1.        , 0.27917028, 0.75027849],\n",
       "       [0.        , 0.80774438, 0.59914393],\n",
       "       [0.        , 0.55317458, 0.98012394],\n",
       "       [0.        , 0.85040966, 0.98600488],\n",
       "       [0.        , 0.85757051, 0.26623247],\n",
       "       [1.        , 0.60249968, 0.81076311],\n",
       "       [1.        , 0.30311802, 0.75822618],\n",
       "       [0.        , 0.26274802, 0.94029184],\n",
       "       [0.        , 0.79885286, 0.24090606],\n",
       "       [0.        , 0.97522263, 0.94417752],\n",
       "       [0.        , 0.78586772, 0.45618212],\n",
       "       [0.        , 0.12951472, 0.88462093],\n",
       "       [0.        , 0.70513834, 0.384869  ],\n",
       "       [0.        , 0.33950922, 0.99890329],\n",
       "       [0.        , 0.38264317, 0.99200835],\n",
       "       [0.        , 0.91329464, 0.97236399],\n",
       "       [0.        , 0.62749475, 0.38905716],\n",
       "       [1.        , 0.35565825, 0.67606026],\n",
       "       [0.        , 0.35728509, 0.90976143],\n",
       "       [0.        , 0.62377382, 0.9494287 ],\n",
       "       [0.        , 0.74466317, 0.87688651],\n",
       "       [0.        , 0.72523327, 0.51849991],\n",
       "       [0.        , 0.64601538, 0.96689985],\n",
       "       [0.        , 0.39984921, 0.90194525],\n",
       "       [1.        , 0.98462518, 0.21860149],\n",
       "       [0.        , 0.34578706, 0.88014851],\n",
       "       [1.        , 0.7923283 , 0.3111131 ],\n",
       "       [0.        , 0.69118792, 0.96834998],\n",
       "       [1.        , 0.27274373, 0.84140898],\n",
       "       [0.        , 0.86178078, 0.15493969],\n",
       "       [0.        , 0.89060613, 0.64875588],\n",
       "       [1.        , 0.82756608, 0.75968108],\n",
       "       [1.        , 0.73001932, 0.8577221 ],\n",
       "       [0.        , 0.51968134, 0.65155162],\n",
       "       [1.        , 0.74399107, 0.2589587 ],\n",
       "       [1.        , 0.46483832, 0.69997683],\n",
       "       [1.        , 0.58561342, 0.75510373],\n",
       "       [1.        , 0.96765329, 0.34239758],\n",
       "       [1.        , 0.8711763 , 0.13492605],\n",
       "       [1.        , 0.88409196, 0.84647965],\n",
       "       [0.        , 0.34142659, 0.85990637],\n",
       "       [1.        , 0.42817328, 0.74668517],\n",
       "       [0.        , 0.42443144, 0.98959646],\n",
       "       [0.        , 0.51028614, 0.49316849],\n",
       "       [0.        , 0.97266861, 0.16391655],\n",
       "       [0.        , 0.62055728, 0.49938325],\n",
       "       [1.        , 0.84921107, 0.84386503],\n",
       "       [0.        , 0.36421068, 0.98200146],\n",
       "       [0.        , 0.7268126 , 0.3808992 ],\n",
       "       [0.        , 0.54261723, 0.96376178],\n",
       "       [0.        , 0.8851341 , 0.95454787],\n",
       "       [1.        , 0.45424911, 0.83363802],\n",
       "       [1.        , 0.5547608 , 0.78424582],\n",
       "       [1.        , 0.77035212, 0.61323734],\n",
       "       [0.        , 0.66497778, 0.969821  ],\n",
       "       [0.        , 0.38386953, 0.94294682],\n",
       "       [0.        , 0.92772038, 0.13441752],\n",
       "       [0.        , 0.2211538 , 0.94535625]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nonconformist.cp import TcpClassifier\n",
    "from nonconformist.nc import NcFactory\n",
    "\n",
    "\n",
    "model = base_classifier(random_state = random_state, min_samples_leaf=min_samples_leaf)\t# Create the underlying model\n",
    "nc = NcFactory.create_nc(model)\t# Create a default nonconformity function\n",
    "tcp = TcpClassifier(nc)\t\t\t# Create a transductive conformal classifier\n",
    "\n",
    "tcp.fit(train_x,train_y)\n",
    "prediction = tcp.predict(test_x, significance=0.7)\n",
    "prediction = tcp.predict_conf(test_x)\n",
    "\n",
    "prediction\n",
    "# test_x[[0,1], :]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
